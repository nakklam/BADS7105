{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd16929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pythainlp\n",
    "from pythainlp.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "import string\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import re\n",
    "pyLDAvis.enable_notebook()\n",
    "import sefr_cut\n",
    "sefr_cut.load_model(engine='tl-deepcut-ws1000')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02502ea",
   "metadata": {},
   "source": [
    "# 1. Load and View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('./data/CustomerReviews.csv')\n",
    "print(\"Review Dimension (num reviews/num columns) : \",review_df.shape)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3695c",
   "metadata": {},
   "source": [
    "# 2. Text Processing\n",
    "‚Ä¢ Text Wrangling ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏ï‡πà‡∏≤‡∏á‡πÜ <br>\n",
    "‚Ä¢ ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8de8c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Text Cleansing\n",
    "# to correct misspelling word and remove the unwanted word or character\n",
    "correct_word_list = {\n",
    "    '‡πÇ‡∏°‡πÇ‡∏°‡πà' : 'momo', '‡∏°‡∏≤‡∏Å‡∏Å' : '‡∏°‡∏≤‡∏Å', '‡∏Å‡∏Å‡∏Å' : '‡∏Å', '‡πÅ‡∏ß‡∏ó' : 'vat', '‡∏û‡∏¥‡∏ã‡πÄ‡∏ã‡∏≠‡πÄ‡∏£‡∏µ‡∏¢' : 'pizzeria', '‡∏û‡∏¥‡∏ã‡∏ã‡πà‡∏≤' : 'pizza', \n",
    "    '‡πÄ‡∏Å‡πâ‡∏ö' : '‡πÄ‡∏Å‡πá‡∏ö', '‡∏ä‡∏π‡∏ä‡∏¥' : '‡∏ã‡∏π‡∏ä‡∏¥', '‡∏ã‡∏∂‡∏õ' : '‡∏ã‡∏∏‡∏õ', '‡∏ä‡∏≤‡∏ö‡∏π‡∏ä‡∏¥' : 'shabushi', '‡∏≠‡∏≤‡∏£‡∏≤‡∏°‡∏ì‡πå' : '‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå', '‡∏™‡πà‡∏á‡∏ô' : '‡∏™‡πà‡∏ß‡∏ô', \n",
    "    '‡∏™‡πÑ‡∏•‡∏ï‡πå' : '‡∏™‡πÑ‡∏•‡∏î‡πå', '‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Ñ‡∏Å‡πå' : '‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå', '‡πÑ‡∏≠‡∏ï‡∏¥‡∏°' : 'icecream', '‡∏û‡∏≤‡∏£‡∏≤‡πÑ‡∏î‡∏™‡πå' : 'paradise', '‡∏û‡∏≤‡∏£‡∏≤‡πÑ‡∏î‡∏ã‡πå' : 'paradise', \n",
    "    '‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó' : 'update', '‡∏ô‡∏≤‡∏£‡∏≤‡∏¢' : 'narai ', '‡∏û‡∏£‡∏µ‡πÄ‡∏°‡∏µ‡πà‡∏¢‡∏°' : '‡∏û‡∏£‡∏µ‡πÄ‡∏°‡∏µ‡∏¢‡∏°','‡∏ö‡πã‡∏ß‡∏¢' : '‡∏ö‡πä‡∏ß‡∏¢', '‡πÄ‡∏ü‡∏£‡∏ô‡πÑ‡∏ä‡∏™‡πå' : '‡πÅ‡∏ü‡∏£‡∏ô‡πÑ‡∏ä‡∏™‡πå',\n",
    "    '‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå‡πà‡∏ï‡πå‡∏ï‡πå‡∏ï‡πå':'‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå','‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå‡πà‡∏ï‡πå‡∏ï‡πå':'‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå','‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå‡∏ï‡πå':'‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå',\n",
    "    '‡∏ö‡∏∏‡∏û‡πÄ‡∏ü‡πà' : '‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå','‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà' : '‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå','‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü' : '‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå', '‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡∏ï' : '‡∏ö‡∏∏‡∏ü‡πÄ‡∏ü‡πà‡∏ï‡πå',\n",
    "    '‡∏£‡∏™‡∏ä‡∏≤‡∏ï' : '‡∏£‡∏™‡∏ä‡∏≤‡∏ï‡∏¥'\n",
    "}\n",
    "\n",
    "unwanted_words = ['(', ')' ,'üòÜ','ü§£','\"','','%','\\u200b','::']\n",
    "\n",
    "def do_text_preprocessing(text):\n",
    "    # 1. correct some misspelling in text\n",
    "    for old,new in correct_word_list.items():\n",
    "        text = text.replace(old, new)\n",
    "        \n",
    "    # 2. remove unwanted word\n",
    "    for word in unwanted_words:\n",
    "        text = text.replace(word, '')\n",
    "        \n",
    "    # 3. remove punctuations character in text\n",
    "    text = re.sub(r'[‡πÜ‡∏Ø!#$&%\\\"\\'()*+,-./:;<=>?@\\[\\]\\\\^_`{}|~]',' ', text)\n",
    "    \n",
    "\n",
    "    # 4. remove digit character in text\n",
    "    text = re.sub(r'\\d',' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# the review text is the review's headline and contents\n",
    "review_df['review_text'] = review_df.apply(lambda x: do_text_preprocessing(x['Headline'] + ' ' + x['Review']), axis=1)\n",
    "print(review_df['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word segmentation and remove the common words(stop words)\n",
    "thai_stopwords = list(pythainlp.corpus.thai_stopwords())\n",
    "unwanted_word = ['‡∏£‡πâ‡∏≤‡∏ô','‡∏ö‡∏≤‡∏ó','‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö','‡∏ä‡∏∑‡πà‡∏≠','‡∏ó‡∏≤‡∏ô','‡∏î‡∏µ','‡∏Å‡∏¥‡∏ô','‡∏≠‡∏≤‡∏´‡∏≤‡∏£',\n",
    "                 '‡∏î‡∏π','‡∏Ñ‡∏ô','‡∏ï‡∏±‡∏ß','‡∏•‡∏≠‡∏á','‡∏ï‡∏≠‡∏ô','‡πÄ‡∏•‡∏∑‡∏≠‡∏Å','‡πÉ‡∏à','‡∏ó‡∏µ‡πà']\n",
    "remove_word_list = thai_stopwords + unwanted_word\n",
    "\n",
    "def do_word_tokenization(text):\n",
    "    word_list = []\n",
    "    for sentence in sent_tokenize(text, engine='whitespace+newline'):\n",
    "        for words in sefr_cut.tokenize(sentence,k=100):\n",
    "            for word in words:\n",
    "                if len(word) >1 and word not in remove_word_list:\n",
    "                    word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "%time review_df['review_token'] = review_df['review_text'].apply(do_word_tokenization)\n",
    "print(review_df['review_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc82b8",
   "metadata": {},
   "source": [
    "# 3. Topic Models with Gensim\n",
    "Gensim ‡πÄ‡∏õ‡πá‡∏ô framework ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ Topic Model, Text Similarity, Sematic Analytics ‡πÅ‡∏•‡∏∞ Text Summarization ‡πÇ‡∏î‡∏¢ Gensim ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6bf3f",
   "metadata": {},
   "source": [
    "### 3.1 Create a dictionary representation of the user's reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_token_list = review_df['review_token'].tolist()\n",
    "dictionary = gensim.corpora.Dictionary(review_token_list)\n",
    "print(f'Number of Vocabulary : {len(dictionary)} \\n')\n",
    "print(f'Dictionary Items : {list(dictionary.items())[:30]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming review list into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in review_token_list]\n",
    "print(bow_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03432e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total papers in the corpus\n",
    "print('Total number of corpus:', len(bow_corpus))\n",
    "\n",
    "# viewing actual terms and their counts\n",
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa1eb2",
   "metadata": {},
   "source": [
    "### 3.2 Topic Models with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "TOTAL_TOPICS = 5\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, \n",
    "                                   id2word=dictionary, \n",
    "                                   chunksize=1000, \n",
    "                                   alpha='auto', \n",
    "                                   eta='auto', \n",
    "                                   random_state=42,\n",
    "                                   iterations=500, \n",
    "                                   num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, \n",
    "                                   eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798c193",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282af023",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00150e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, \n",
    "                                                      corpus=bow_corpus, \n",
    "                                                      texts=review_token_list,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, \n",
    "                                                         corpus=bow_corpus, \n",
    "                                                         texts=review_token_list,\n",
    "                                                         dictionary=dictionary, \n",
    "                                                         coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bffa66",
   "metadata": {},
   "source": [
    "### 3.3 Finding Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea90b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
    "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
    "                                    cpus=1):\n",
    "    \n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        lda_model = gensim.models.LdaModel(corpus=bow_corpus, \n",
    "                                           id2word=dictionary, \n",
    "                                           chunksize=1740,\n",
    "                                           alpha='auto', \n",
    "                                           eta='auto', \n",
    "                                           random_state=42,\n",
    "                                           iterations=500, \n",
    "                                           num_topics=topic_nums,\n",
    "                                           passes=20,\n",
    "                                           eval_every=None)\n",
    "        \n",
    "        cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, \n",
    "                                                      corpus=bow_corpus, \n",
    "                                                      texts=review_token_list,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(lda_model)\n",
    "    \n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, \n",
    "                                                               texts=review_token_list,\n",
    "                                                               dictionary=dictionary, \n",
    "                                                               start_topic_count=2,\n",
    "                                                               end_topic_count=15, \n",
    "                                                               step=1, cpus=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92368017",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 16, 1),\n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2, 16, 1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_ax, y_ax, c='r')\n",
    "plt.axhline(y=0.3423, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "xl = plt.xlabel('Number of Topics')\n",
    "yl = plt.ylabel('Coherence Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 7].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "                   for n in range(0, best_lda_model.num_topics)]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
    "                              for topic in topics],\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
    "                         )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58c4f8",
   "metadata": {},
   "source": [
    "# 4. Print Result from Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "tm_results = best_lda_model[bow_corpus]\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
    "                     for topics in tm_results]\n",
    "\n",
    "# result_df['Restaurant'] = review_df['Restaurant']\n",
    "result_df['User'] = review_df['User']\n",
    "result_df['Review'] = review_df['review_text']\n",
    "result_df['Selected Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "result_df['Topic Text'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import option_context\n",
    "\n",
    "with option_context('display.max_colwidth', 100):\n",
    "    display(result_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
