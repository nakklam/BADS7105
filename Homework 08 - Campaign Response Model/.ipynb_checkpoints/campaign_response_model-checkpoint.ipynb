{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : ธีรพงค์ ศันสนียวรรธน์ <br>\n",
    "Date : 23 May 2564 <br>\n",
    "Description : <br>\n",
    "เป็นการใช้ข้อมูลเพื่อช่วยในการทำนายว่าลูกค้าจะทำการตอบรับ Campaign ที่มีการจัดส่งให้กับลูกค้าหรือไม่ <br> <br>\n",
    "\n",
    "เป็นส่วนหนึ่งของวิชา BADS 7105 Customer Analytics <br>\n",
    "อาจารย์ผู้สอน ดร. ธนชาตย์ ฤทธิ์บำรุง <br> <br>\n",
    "สาขาวิชาการวิเคราะธ์ธุรกิจและวิทยาการข้อมูล DS รุ่นที่ 5 <br>\n",
    "คณะสถิติประยุกต์ <br>\n",
    "สถาบันบัณฑิตพัฒนบริหารศาสตร์ (นิด้า) NIDA <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZKtUVUUXnTv"
   },
   "source": [
    "# Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2595,
     "status": "ok",
     "timestamp": 1603475318871,
     "user": {
      "displayName": "Thanachart Ritbumroong",
      "photoUrl": "",
      "userId": "18414212507793256437"
     },
     "user_tz": -420
    },
    "id": "UAbXlD4jLPsq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, roc_curve, auc\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import plot_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11398,
     "status": "ok",
     "timestamp": 1603475327678,
     "user": {
      "displayName": "Thanachart Ritbumroong",
      "photoUrl": "",
      "userId": "18414212507793256437"
     },
     "user_tz": -420
    },
    "id": "ki6FxV4YXxbX"
   },
   "outputs": [],
   "source": [
    "# ข้อมูล Transaction การซื้อสินค้าของลูกค้า\n",
    "trans_df = pd.read_csv('./data/Retail_Data_Transactions.csv', parse_dates=['trans_date'])\n",
    "# ข้อมูลการตอบรับ Campaign ของลูกค้า\n",
    "resp_df = pd.read_csv('./data/Retail_Data_Response.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 สำรวจข้อมูลชุด Retail_Data_Transactions\n",
    "### 2.1.1 ทำการดูข้อมูลที่โหลดมาว่ามี Columm ชื่ออะไรบ้าง และในแต่ละ Column นั้นเก็บข้อมูลเป็นอย่างไร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 11383,
     "status": "ok",
     "timestamp": 1603475327680,
     "user": {
      "displayName": "Thanachart Ritbumroong",
      "photoUrl": "",
      "userId": "18414212507793256437"
     },
     "user_tz": -420
    },
    "id": "jknwtDiZYQvq",
    "outputId": "0b0fa2f6-23ce-4d81-d9ff-1a92cc6f0113"
   },
   "outputs": [],
   "source": [
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data distribution\n",
    "sns.countplot(x='tran_amount', data=trans_df)\n",
    "plt.title('Distribution of Amount', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 ทำการตรวจสอบข้อมูลว่ามีข้อมูลเป็น null และมีข้อมูลแถวไหนที่ซ้าซ้อนหรือไม่"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null\n",
    "trans_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 11377,
     "status": "ok",
     "timestamp": 1603475327680,
     "user": {
      "displayName": "Thanachart Ritbumroong",
      "photoUrl": "",
      "userId": "18414212507793256437"
     },
     "user_tz": -420
    },
    "id": "sPQ1BvchYTy_",
    "outputId": "a33b2f67-86da-4092-fe4f-bf1f9d15dfd5"
   },
   "outputs": [],
   "source": [
    "# check dupplicate data\n",
    "print(\"Duplicate Rows :\",trans_df.duplicated().sum())\n",
    "print(trans_df[trans_df.duplicated()==True])\n",
    "\n",
    "# found duplicated row and delete them by keeping only the first found row.\n",
    "trans_df = trans_df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 ทำการตรวจสอบข้อมูล Transaction ว่าข้อมูลที่จัดเก็บจัดเก็บการซื้อสินค้าของ Customer ไว้อย่างไร\n",
    "จากการตรวจสอบพบว่า มี Transaction ของ Customer แต่ละคน ภายใน 1 วันสามารถมี Transaction ได้มากกว่า 1 Transaction\n",
    "ดัวยเหตุนี้ ในขั้นตอน Feature Engineering จะทำการกำหนดว่า ถ้าเป็นลูกค้าคนเดียวกัน จะกำหนดให้ Transaction ข้อลูกค้า\n",
    "คนนั้นที่เป็นขึ้นภายในวันเดียวกัน เป็น Basket Id เดียวกัน (ความเป็นจริงแล้วอาจจะเป็นคนละ Basket ก็ได้ ถ้าลูกค้าคนนั้น ภายใน\n",
    "เวลา 1 วันมีการกลับเข้ามาซื้อมากกว่า 1 ครั้ง แต่ในการวิเคราะห์นี้จะถือว่าเป็น Basket ID เดียวกัน)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# found a customer bought the same day\n",
    "grouping = trans_df.groupby(['customer_id','trans_date']).count().reset_index()\n",
    "grouping[grouping.tran_amount>1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# investigate statatistic data\n",
    "trans_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 สำรวจข้อมูลชุด Retail_Data_Response\n",
    "### 2.2.1 ทำการดูข้อมูลที่โหลดมาว่ามี Columm ชื่ออะไรบ้าง และในแต่ละ Column นั้นเก็บข้อมูลเป็นอย่างไร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทำการดูจำนวนข้อมูลที่ใช้ในการ Predict ของทั้ง 2 Class ซึ่งพบว่าข้อมูลที่เป็นข้อมูลแบบ Imbalaced dataset คือ ข้อมูลที่ระบุว่ามีการตอบรับ Campaign มีจำนวนน้อยกว่าข้อมูลที่ระบุว่าไม่ตอบรับ Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='response', data=resp_df)\n",
    "plt.title('Distribution of Response', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVsmfx7aYtmB"
   },
   "source": [
    "# 3. Feature Engineering\n",
    "การบวนการใช้ความรู้ใน Domain นั้นๆ เพื่อสร้าง Feature ใหม่ๆ ขึ้นมา ซึ่ง Feature เหล่านี้จะช่วยทำให้อัลกอริทึมมีการเรียนรู้ได้ดีมากขึ้น ตัวอย่างเช่น เติมข้อมูลที่ขาด หรือจัดแบ่งเป็นกลุ่มเป็นต้น สำหรับใน Assignment นี้จะนำเอาความรู้ในเรื่องของ RFM มาใช้\n",
    "\n",
    "## RFM (Recency, Frequency, and Monetary)\n",
    "คือ เทคนิคที่ใช้ข้อมูลเกี่ยวกับพฤติกรรมการซื้อของของลูกค้า 3 ปัจจัยมาใช้ในการวิเคราะห์ ซึ่งก็คือ\n",
    "\n",
    "a) Recency (R) : ลูกค้ามีการซื้อสินค้าครั้งล่าสุดนานแล้วแค่ไหน? <br>\n",
    "b) Frequency (F): ลูกค้ามีการซื้อสินค้าบ่อยแค่ไหน? <br>\n",
    "c) Monetary : มูลค่าในการซื้อสินค้่าเยอะมากแค่ไหน? <br>\n",
    "\n",
    "ประโยชน์ของ RFM คือ ถ้าลูกค้าพึ่งมาซื้อสินค้าได้ไม่นาน มีการซื้ออยู่เป็นประจำ และมีปริมาณการซื้อเยอะ ย่อมต้องมีโอกาศที่จะตอบรับ Campaign ที่เราส่งให้สูกว่านั่นเอง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 หาวันที่จะทำการ Predict\n",
    "ในการทำนาย Campaign Response จะมีการระบุวันที่จะทำนาย ใน Assignment นี้จะเลือกวันที่ทำนาย เป็นวันถัดมาของ Transaction สุดท้ายที่มีใน Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Oldest Transaction Date : \",trans_df['trans_date'].min())\n",
    "print(\"Newest Transaction Date : \",trans_df['trans_date'].max())\n",
    "\n",
    "# select the next day of the last transaction\n",
    "campaign_date = trans_df['trans_date'].max() + dt.timedelta(days=1)\n",
    "print(\"Campaign Date : \",campaign_date)\n",
    "\n",
    "trans_df['campaign_date'] = campaign_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 สร้าง Feature ชื่อ Basket ID \n",
    "จะให้ทุกๆ Transaction ของลูกค้าคนเดียวกัน จะมีต่า Basket ID เดียวกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# customer who bought product within the same day, it will be the same basket id\n",
    "trans_df['basket_id'] = trans_df['customer_id'].astype(str) +'#'+ trans_df['trans_date'].astype(str)\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 แปลงข้อมูลในรูป Transaction เป็นข้อมูลสรุปรายเดือน\n",
    "ทำการสร้าง Feature เพื่อระบุเดือนของแต่ละ Transaction ข้อมูลนี้ไว้ใช้เพื่อดูลักษณะข้อมูลของลุกค้าในระดับรายเดือน นอกเหนือจากการดูลักษณะของข้อมูลในระดับ Transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 แปลง transaction date จากที่ระบุว่าเป็นรายวันไปเป็นระบุเป็นรายเดือน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjust_in_month(x) : \n",
    "    return dt.datetime(x.year,x.month,1)\n",
    "\n",
    "# tranform transaction's date of each transaction to transaction's month\n",
    "trans_df['trans_in_month'] = trans_df['trans_date'].apply(get_adjust_in_month)\n",
    "# find the first month of transaction of each customer\n",
    "trans_df['start_trans_in_month'] = trans_df.groupby('customer_id')['trans_in_month'].transform('min')\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 คำนวนหาระยะเวลาความเป็นลูกค้าของแต่ละ Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_year(df,col_name): \n",
    "    year_value = df[col_name].dt.year\n",
    "    month_value = df[col_name].dt.month\n",
    "    return year_value,month_value\n",
    "\n",
    "# get the start transaction of each customer\n",
    "trans_df['start_year'],trans_df['start_month'] = get_month_year(trans_df,'start_trans_in_month')\n",
    "\n",
    "# calculate the customer's period from first purchase's date to campaign' date of each customer\n",
    "campaign_year,campaign_month = get_month_year(trans_df,'campaign_date')\n",
    "total_year_diff = campaign_year - trans_df['start_year']\n",
    "total_month_diff = campaign_month - trans_df['start_month']\n",
    "trans_df['customer_month'] = total_year_diff * 12 + total_month_diff + 1\n",
    "\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.3 สร้างข้อมูล Customer Single View จากข้อมูล RFM\n",
    "ข้อมูล Customer Single View คือ การสรุปทุกสิ่งทุกอย่างของลูกค้า 1 คนให้เหลือข้อมูลเพียงแค่ 1 record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RFM metrics\n",
    "customer_df = trans_df.groupby(['customer_id']).agg(\n",
    "    {'trans_date': lambda x : (campaign_date - x.max()).days, # last visit\n",
    "     'basket_id': pd.Series.nunique, # total visit\n",
    "     'tran_amount': 'sum', # total spend\n",
    "     'customer_month': 'max'\n",
    "    }).reset_index() \n",
    "\n",
    "#Rename columns\n",
    "customer_df.rename(columns={'trans_date':'recency',\n",
    "                            'basket_id':'total_frequency', # total visit\n",
    "                            'tran_amount':'total_monetary'} # total spend\n",
    "                   ,inplace= True)\n",
    "#Final RFM values\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict Campaign Reponse #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 merge 2 datasets (Customer's data and Campaign respose's data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filter ข้อมูลที่เป็น null\n",
    "predict_df = customer_df.merge(resp_df,on=['customer_id'],how='left')\n",
    "print(\"Null columns\",predict_df.isnull().sum())\n",
    "\n",
    "predict_df = predict_df[~predict_df.response.isnull()]\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_prediction(X,y):\n",
    "    # split train and test dataset\n",
    "    RANDOM_STATE = 18\n",
    "    TEST_SIZE = 0.3\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    \n",
    "    print(\"\\nDimension of train and test data: -------------\")\n",
    "    print(\"X_train dataset: \", X_train.shape)\n",
    "    print(\"y_train dataset: \", y_train.shape)\n",
    "    print(\"X_test dataset: \", X_test.shape)\n",
    "    print(\"y_test dataset: \", y_test.shape)\n",
    "    \n",
    "    # fix imbalanced data with SMOTE\n",
    "    # เพิ่มตัวอย่าง Minority Class ให้มีปริมาณมากขึ้น (Oversampling) \n",
    "    sm = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_sm, y_sm = sm.fit_resample(X_train, y_train)\n",
    "    print(\"\\nDimension after fixing imbalance issue: -------------\")\n",
    "    print(\"X_sm dataset: \", X_sm.shape)\n",
    "    print(\"y_sm dataset: \", y_sm.shape)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc')\n",
    "    xgb_model.fit(X_sm, y_sm, early_stopping_rounds=5, eval_set=[(X_test, y_test)])\n",
    "\n",
    "    y_train_pred = xgb_model.predict(X_sm)\n",
    "    print('\\nTraining Set\\'s Results ------------------------------------\\n')\n",
    "    print(classification_report(y_sm, y_train_pred))\n",
    "\n",
    "    y_test_pred = xgb_model.predict(X_test)\n",
    "    print('\\nTesting Set\\'s Results ------------------------------------\\n')\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    # plot ROC Curve\n",
    "    plt.figure(figsize=(10,6))\n",
    "    y_prob_sm = xgb_model.predict_proba(X_sm)\n",
    "    fpr_train, tpr_train ,_ = roc_curve(y_sm, y_prob_sm[:,1])\n",
    "    auc_train = roc_auc_score(y_sm, y_prob_sm[:,1])\n",
    "\n",
    "    plt.plot(fpr_train, tpr_train, color='red', label=f'Train set, auc = {auc_train:.2f}')\n",
    "\n",
    "    # test set\n",
    "    y_prob_test = xgb_model.predict_proba(X_test.to_numpy())\n",
    "    fpr_test, tpr_test ,_ = roc_curve(y_test, y_prob_test[:,1])\n",
    "    auc_test = roc_auc_score(y_test, y_prob_test[:,1])\n",
    "\n",
    "    plt.plot([0,1],[0,1], color = 'grey', lw=2, ls ='--')\n",
    "\n",
    "    plt.plot(fpr_test, tpr_test, color='blue', label=f'Test set, auc = {auc_test:.3f}')\n",
    "    plt.legend()\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = predict_df[['recency','total_frequency','total_monetary']]\n",
    "y = predict_df['response']\n",
    "print(\"X: ----------------\")\n",
    "print(X.head())\n",
    "print(\"\\ny: ----------------\")\n",
    "print(y.head())\n",
    "\n",
    "campaign_prediction(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict Campaign Reponse #2\n",
    "## 5.1 Feature engineering (ฉบับปรับปรุง #1)\n",
    "### หาค่าเฉลี่ยจำนวนการซื้อ และปริมาณการซื้อ\n",
    "\n",
    "จากสาเหตุที่ลูกค้าแต่ละคนเริ่มเข้ามาซื้อในเวลาที่ไม่พร้อมกัน ดังนั้นการใช้ feature totl_visit และ total_spend ก็จะมีผลทำให้การตีความค่าสถิติที่ได้นั้นต่ำกว่าความเป็นจริงได้ ดังนี้จึงควรเป็นค่าเฉลี่ย และเฉลี่ยนับจากวันที่ลูกค้าคนนั้นเริ่มเข้ามาเป็นลูกค้าวันแรก"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['avg_frequency'] = customer_df['total_frequency']/customer_df['customer_month']\n",
    "customer_df['avg_monetary'] = customer_df['total_monetary']/customer_df['customer_month']\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 merge 2 datasets (Customer's data and Campaign respose's data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ข้อมูลที่เป็น null\n",
    "predict_df = customer_df.merge(resp_df,on=['customer_id'],how='left')\n",
    "print(\"Null columns\",predict_df.isnull().sum())\n",
    "\n",
    "predict_df = predict_df[~predict_df.response.isnull()]\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 predict campaing response #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = predict_df[['recency','avg_frequency','avg_monetary']]\n",
    "y = predict_df['response']\n",
    "print(\"X: ----------------\")\n",
    "print(X.head())\n",
    "print(\"\\ny: ----------------\")\n",
    "print(y.head())\n",
    "\n",
    "campaign_prediction(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predict Campaign Reponse #3\n",
    "## 6.1 Feature engineering (ฉบับปรับปรุง #2)\n",
    "### จัดกลุ่มค่า recency, avg_frequency, avg_monetary ออกเป็น 5 กลุ่ม และคำนวนออกมาเป็นค่า rfm score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building RFM Features\n",
    "customer_df['r'] = pd.qcut(customer_df['recency'], q=5, labels = range(5,0,-1)).astype(int)\n",
    "customer_df['f'] = pd.qcut(customer_df['avg_frequency'],q=5, labels = range(1, 6)).astype(int)\n",
    "customer_df['m'] = pd.qcut(customer_df['avg_monetary'],q=5,labels = range(1, 6)).astype(int)\n",
    "customer_df['rfm_score'] = customer_df[['r','f','m']].sum(axis=1)\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 merge 2 datasets (Customer's data and Campaign respose's data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter ข้อมูลที่เป็น null\n",
    "predict_df = customer_df.merge(resp_df,on=['customer_id'],how='left')\n",
    "print(\"Null columns\",predict_df.isnull().sum())\n",
    "\n",
    "predict_df = predict_df[~predict_df.response.isnull()]\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 predict campaing response #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = predict_df[['recency','avg_frequency','avg_monetary','r','f','m','rfm_score']]\n",
    "y = predict_df['response']\n",
    "\n",
    "print(\"X: ----------------\")\n",
    "print(X.head())\n",
    "print(\"\\ny: ----------------\")\n",
    "print(y.head())\n",
    "\n",
    "campaign_prediction(X,y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPB/V7EnPAg5F7QOuHnmerW",
   "collapsed_sections": [
    "5ZKtUVUUXnTv",
    "uVsmfx7aYtmB",
    "F26FEqtAZ9hK",
    "pfCzlW-HbZNo",
    "MKLeuoi5c_t2",
    "QIxuTrNCita2",
    "BqiXugl6jIuz"
   ],
   "name": "Campaign Response Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
